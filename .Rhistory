install.packages('tidyrss'
)
library(packrat)
install.packages("packrat")
packrat::init()
install.packages("tidyRSS")
install.packages("dplyr")
snapshot()
packrat::snapshot()
library(tidyRSS)
library(dplyr)
install.packages("googlesheets4")
packrat::snapshot()
# testing first source: Public Source
public_source <- tidyfeed('https://publicsource.org/feed/')
View(public_source)
#VOSD
vosd <- tidyfeed("https://www.voiceofsandiego.org/category/topics/feed/")
View(vosd)
# Honolulu Civil Beat
honolulu <- tidyfeed("https://www.civilbeat.org/feed/")
View(honolulu)
# Texas Tribune
tt <- tidyfeed("https://feeds.texastribune.org/feeds/main/")
View(tt)
write.csv(honolulu, "honolulu.csv")
class(honolulu)
str(honolulu)
View(tt)
write.csv(honolulu[1:13], "honolulu.csv")
library(tidyRSS)
library(dplyr)
library(googlesheets4)
data <- read_sheet("https://docs.google.com/spreadsheets/d/12qBxLkx1_H5qQgsVDyf0FP3PasunNnpR3pDwd-qY_xM/edit#gid=0", sheet = 2)
View(data)
data$rss <- ifelse(is.na(data$rss), paste0(data$base_rss, data$section), data$rss)
df_list <- lapply(data$rss, tidyfeed)
data$rss <- ifelse(is.na(data$rss), paste0(data$base_rss, data$section, ".xml"), data$rss)
df_list <- lapply(data$rss, tidyfeed)
data <- read_sheet("https://docs.google.com/spreadsheets/d/12qBxLkx1_H5qQgsVDyf0FP3PasunNnpR3pDwd-qY_xM/edit#gid=0", sheet = 2)
data$rss <- ifelse(is.na(data$rss), paste0(data$base_rss, data$section, ".xml"), data$rss)
df_list <- lapply(data$rss, tidyfeed)
df_list$rss[6]
data$rss[6]
data <- read_sheet("https://docs.google.com/spreadsheets/d/12qBxLkx1_H5qQgsVDyf0FP3PasunNnpR3pDwd-qY_xM/edit#gid=0", sheet = 2)
data$rss <- ifelse(is.na(data$rss), paste0(data$base_rss, data$section, ".xml"), data$rss)
df_list <- lapply(data$rss, tidyfeed)
data <- read_sheet("https://docs.google.com/spreadsheets/d/12qBxLkx1_H5qQgsVDyf0FP3PasunNnpR3pDwd-qY_xM/edit#gid=0", sheet = 2)
data$rss <- ifelse(is.na(data$rss), paste0(data$base_rss, data$section, ".xml"), data$rss)
df_list <- lapply(data$rss, tidyfeed)
df_list <- lapply(data$rss, function(x) {
print(x)
tidyfeed(x)
})
df_list <- lapply(data$rss[106:nrow(data), ], function(x) {
print(x)
tidyfeed(x)
})
df_list <- lapply(data$rss[106:nrow(data)], function(x) {
print(x)
tidyfeed(x)
})
df_list <- lapply(data$rss[107:nrow(data)], function(x) {
print(x)
tidyfeed(x)
})
df_list <- lapply(data$rss[111:nrow(data)], function(x) {
print(x)
tidyfeed(x)
})
data <- read_sheet("https://docs.google.com/spreadsheets/d/12qBxLkx1_H5qQgsVDyf0FP3PasunNnpR3pDwd-qY_xM/edit#gid=0", sheet = 2)
data$rss <- ifelse(is.na(data$rss), paste0(data$base_rss, data$section, ".xml"), data$rss)
df_list <- lapply(data$rss, function(x) {
print(x)
tidyfeed(x)
})
df_list <- lapply(data$rss[155: , ], function(x) {
print(x)
tidyfeed(x)
})
df_list <- lapply(data$rss[155:nrow(data) , ], function(x) {
print(x)
tidyfeed(x)
})
df_list <- lapply(data$rss[155:nrow(data)], function(x) {
print(x)
tidyfeed(x)
})
data <- read_sheet("https://docs.google.com/spreadsheets/d/12qBxLkx1_H5qQgsVDyf0FP3PasunNnpR3pDwd-qY_xM/edit#gid=0", sheet = 2)
data <- read_sheet("https://docs.google.com/spreadsheets/d/12qBxLkx1_H5qQgsVDyf0FP3PasunNnpR3pDwd-qY_xM/edit#gid=0", sheet = 2)
data$rss <- ifelse(is.na(data$rss), paste0(data$base_rss, data$section, ".xml"), data$rss)
df_list <- lapply(data$rss[178:186], function(x) {
print(x)
tidyfeed(x)
})
df_list <- lapply(data$rss[178:185], function(x) {
print(x)
tidyfeed(x)
})
data$rss <- ifelse(is.na(data$rss), paste0(data$base_rss, data$section, ".xml"), data$rss)
df_list <- lapply(data$rss, function(x) {
print(x)
tidyfeed(x)
})
View(data)
data <- read_sheet("https://docs.google.com/spreadsheets/d/12qBxLkx1_H5qQgsVDyf0FP3PasunNnpR3pDwd-qY_xM/edit#gid=0", sheet = 2)
data$rss <- ifelse(is.na(data$rss), paste0(data$base_rss, data$section, ".xml"), data$rss)
df_list <- lapply(data$rss, function(x) {
print(x)
tidyfeed(x)
})
df_list <- lapply(data$rss, function(x) {
print(x)
tidyfeed(x)
})
data <- read_sheet("https://docs.google.com/spreadsheets/d/12qBxLkx1_H5qQgsVDyf0FP3PasunNnpR3pDwd-qY_xM/edit#gid=0", sheet = 2)
data$rss <- ifelse(is.na(data$rss), paste0(data$base_rss, data$section, ".xml"), data$rss)
df_list <- lapply(data$rss, function(x) {
print(x)
tidyfeed(x)
})
bind_rows(df_list)
?bind_rows
bind_rows(unlist(df_list))
bind_rows(unlist(df_list))
df <- bind_rows(unlist(df_list))
View(df)
df <- do.call("rbind", unlist(df_list))
df <- do.call("rbind", df_list)
?data$rss
?tidyfeed
nytimes <- data %>% filter(name == "The New York TImes")
nytimes <- data %>% filter(name == "The New York Times")
scmp <- data %>% filter(name == "SCMP")
post <- data %>% filter(name == "The Washington Post")
propublica <- data %>% filter(ame == "ProPublica")
propublica <- data %>% filter(name == "ProPublica")
tidyfeed(x)
df_list <- lapply(nytimes$rss, function(x) {
print(x)
tidyfeed(x)
})
nyt <- do.call("rbind", df_list)
df_list <- lapply(post$rss, function(x) {
print(x)
tidyfeed(x)
})
wapo <- do.call("rbind", df_list)
data <- read_sheet("https://docs.google.com/spreadsheets/d/12qBxLkx1_H5qQgsVDyf0FP3PasunNnpR3pDwd-qY_xM/edit#gid=0", sheet = 2)
data$rss <- ifelse(is.na(data$rss), paste0(data$base_rss, data$section, ".xml"), data$rss)
df_list <- lapply(data$rss, function(x) {
print(x)
tidyfeed(x)
})
length(df_lsit)
length(df_list)
View(df_list)
library(tidyRSS)
library(dplyr)
library(googlesheets4)
# testing ProPublica
pp <- tidyfeed("http://feeds.propublica.org/propublica/main")
View(pp)
webshot::install_phantomjs()
install.packages("webshot")
library(webshot)
webshot::install_phantomjs()
pp$item_guide[1]
pp[1, item_guide]
pp[1, item_guid]
pp[1, pp$item_guid]
pp$item_guid
pp$item_guid[1]
webshot(pp$item_guid[1])
webshot(pp$item_guid[1])
webshot(pp$item_guid[1], delay = 0.6)
lapply(pp$item_guid, function(x) {
webshot(x, file=paste0("screenshots/", x, ".png"))
})
#SCMP
scmp <- tidyfeed("https://www.scmp.com/rss/91/feed")
#SCMP
scmp <- tidyfeed("https://www.scmp.com/rss/91/feed") %>%
slice(1:10)
View(scmp)
lapply(scmp$item_link, function(x) {
webshot(x, file=paste0("screenshots/", x, ".png"))
})
webshot("https://www.scmp.com/news/world/united-states-canada/article/3122009/will-donald-trump-face-criminal-charges")
webshot("https://www.nytimes.com/live/2021/02/17/us/winter-storm-weather-live")
webshot("https://www.washingtonpost.com/politics/2021/02/17/harriss-claim-biden-vaccine-plan-was-starting-scratch/")
webshot("https://www.washingtonpost.com/world/africa/tanzania-coronavirus-magufuli/2021/02/17/896e64cc-7123-11eb-8651-6d3091eac63f_story.html")
webshot("https://www.washingtonpost.com/technology/2021/02/16/amazon-new-york-suit/?itid=hp_national-0109")
webshot("https://www.washingtonpost.com/local/obituaries/rush-limbaugh-dead/2021/02/17/61bacd24-e04b-11e7-8679-a9728984779c_story.html?itid=hp-top-table-main")
webshot("https://www.washingtonpost.com/graphics/2019/national/bears-ears/")
webshot("https://www.washingtonpost.com/graphics/2019/investigations/opioid-pills-overdose-analysis/")
# testing ProPublica
pp <- tidyfeed("http://feeds.propublica.org/propublica/main")
library(tidyRSS)
library(dplyr)
library(googlesheets4)
library(webshot)
# testing ProPublica
pp <- tidyfeed("http://feeds.propublica.org/propublica/main")
View(pp)
library(webshot)
webshot("https://www.nytimes.com/interactive/2021/02/16/us/winter-storm-texas-power-outage-map.html")
webshot("https://www.nytimes.com/interactive/2020/09/02/upshot/america-political-spectrum.html", file ="nytimes2.png")
webshot("https://www.nytimes.com/interactive/2021/upshot/2020-election-map.html", file="nytimes3.jpg")
webshot("https://www.nytimes.com/interactive/2020/us/coronavirus-us-cases.html", file="nytimes4.png")
webshot("https://www.nytimes.com/interactive/2020/us/coronavirus-us-cases.html", file="nytimes4.png", delay = 3)
library(webshot)
webshot("https://www.nytimes.com/interactive/2020/us/coronavirus-us-cases.html", file="nytimes4.png", delay = 3)
webshot("https://www.nytimes.com/interactive/2021/upshot/2020-election-map.html", file="nytimes3.jpg", delay = 3)
webshot("https://www.nytimes.com/interactive/2021/upshot/2020-election-map.html", file="nytimes3.jpg", delay = 3)
webshot("https://www.nytimes.com/interactive/2021/upshot/2020-election-map.html", file="nytimes3.jpg", delay = 10)
webshot("https://www.scmp.com/news/world/united-states-canada/article/3122009/will-donald-trump-face-criminal-charges", delay = 3)
webshot("https://www.scmp.com/news/world/united-states-canada/article/3122009/will-donald-trump-face-criminal-charges", cliprect = "viewport", delay = 3)
webshot("https://www.scmp.com/news/world/united-states-canada/article/3122009/will-donald-trump-face-criminal-charges", selector=".contents", delay = 3)
webshot("https://www.scmp.com/news/world/united-states-canada/article/3122009/will-donald-trump-face-criminal-charges", selector=".data-v-d7b6025c", delay = 3)
webshot("https://www.scmp.com/news/world/united-states-canada/article/3122009/will-donald-trump-face-criminal-charges", selector=".generic-article__body", delay = 3)
packrat::init()
packrat::init()
library(packrat)
packrat::init()
packrat::snapshot()
packrat_mode(on=TRUE)
library(rtweet)
install.packages("screenshots/https:/www.propublica.org/atpropublica/two-propublica-local-reporting-network-projects-named-finalists-for-shadid-award-for-journalism-ethics#1050190.png")
install.packages("rtweet")
library(rtweet)
library(rtweet) # interface with Twitter API
library(rtweet) # interface with Twitter API
## Exploring rtweet package for RSVS studies ##
install.packages("rtweet")
library(rtweet) # interface with Twitter API
install.packages("jsonlite")
library(rtweet) # interface with Twitter API
library(dplyr) # for data wrangling
library(rtweet) # interface with Twitter API
packrat::disable()
library(rtweet) # interface with Twitter API
library(dplyr) # for data wrangling
# AUTHENTICATION #
api_key <- "a7CB7bUNNFrivMuDx96BJU18T"
api_secret <- "tnmAaz1Px4vF7iuxG6EnCn8afg3oa5uFJlfd9gdU3yQyHgmV57"
token <- create_token(
app = "rsvs2",
consumer_key = api_key,
consumer_secret = api_secret
)
library(googlesheets4)
library(rtweet)
library(dplyr)
sources <- read_sheet("https://docs.google.com/spreadsheets/d/12qBxLkx1_H5qQgsVDyf0FP3PasunNnpR3pDwd-qY_xM/edit#gid=0")
pgTL <- get_timeline(user = "87968068", n=100000) # retrieving timeline
View(pgTL)
?getTimeline
?get_timeline
# replace "@" signs in twitter_handle column
sources$twitter_handle <- gsub("@", "", sources$twitter_handle)
head(sources)
duplicated()
?duplicated
sources <- sources[!duplicated(sources$twitter_handle)]
sources <- sources[!duplicated(sources)]
sources <- sources[!duplicated(sources$twitter_handle), ]
?vapply
df_list <- lapply(sources$twitter_handle, function(x) {
print(x)
})
View(df_list)
df_list <- lapply(sources$twitter_handle, function(x) {
})
df_list <- lapply(sources, function(x) {
})
View(df_list)
?get_timlein
?get_timeline
df_list <- lapply(sources$twitter_handle, function(x) {
df <- get_timeline(x, n = 100)
})
df_list <- lapply(sources$twitter_handle, function(x) {
df <- get_timeline(x, n = 300)
})
test <- unlist(df_list)
write_as_csv()
?write_sheet
sheet <- "https://docs.google.com/spreadsheets/d/1k_yYVeMjWVZuTtzvnafQSGMHRQvqDToPGncijWWfMAk/edit#gid=0"
View(df_list)
df_list[[1]]
df_list[[1]][screen_name][1]
df_list[[1]]$screen_name
df_list[[1]]$screen_name[1]
lapply(df_list, function(df) {
sheet <- "https://docs.google.com/spreadsheets/d/1k_yYVeMjWVZuTtzvnafQSGMHRQvqDToPGncijWWfMAk/edit#gid=0"
write_sheet(df, sheet, df_list[[1]]$screen_name[1])
})
lapply(df_list, function(df) {
sheet <- "https://docs.google.com/spreadsheets/d/1k_yYVeMjWVZuTtzvnafQSGMHRQvqDToPGncijWWfMAk/edit#gid=0"
write_sheet(df, sheet, df$screen_name[1])
})
lapply(df_list, function(df) {
lapply(df_list, function(df) {
write.csv(df, paste0("data/processed/study2_sample_0401/", df$screen_name[1], ".csv"))
})
?write.csv
View(df_list)
for (df in df_list) {
write.csv(df, paste0("data/processed/study2_sample_0401/", df$screen_name[1], ".csv"))
}
write.csv(df, paste0("data/processed/study2_sample_0401/", 2, ".csv"))
lapply(df_list, function(df) {
class(df)
# write.csv(df, paste0("data/processed/study2_sample_0401/", df$screen_name[1], ".csv"))
})
write.csv(df)
write.csv(df_list[[1]], "data/processed/study2_sample_0401/test.csv")
class(df_list[[1]])
head(df_list[[1]])
write.csv(as.data.frame(df_list[[1]]), "data/processed/study2_sample_0401/test.csv")
lapply(df_list, function(df) {
df <- apply(df, 2, as.character)
write.csv(df, paste0("data/processed/study2_sample_0401/", df$screen_name[1], ".csv"))
})
lapply(df_list, function(df) {
df <- apply(df, 2, as.character)
head(df)
# write.csv(df, paste0("data/processed/study2_sample_0401/", df$screen_name[1], ".csv"))
})
lapply(df_list, function(df) {
df <- apply(df, 2, as.character)
str(df)
# write.csv(df, paste0("data/processed/study2_sample_0401/", df$screen_name[1], ".csv"))
})
write.csv(df, paste0("data/processed/study2_sample_0401/", "test", ".csv"))
?get_timeline
test_df <- df_list[[1]]
str(test_df)
View(test_df)
View(pgTL)
test_df <- df_list[[1]] %>%
select(urls_t.co)
write.csv(test_df, "data/processed/study2_sample_0401/test.csv")
str(test_df)
class(urls_t.co) <- "character"
class(test_df$urls_t.co) <- "character"
str(test_df)
write.csv(test_df, "data/processed/study2_sample_0401/test.csv")
test_df <- df_list[[1]]
test_df <- apply(test_df, 2, as.character)
write.csv(test_df, "data/processed/study2_sample_0401/test.csv")
test_df <- df_list[[1]]
class(test_df$created_at)
str(test_df$created_at)
lapply(df_list, function(df) {
df_nodate <- apply(df, 2, as.character)
df_nodate <- df_nodate %>%
select(c(user_id, status_id, screen_name, text, url_t.co))
df <- cbind(df_nodate, df$created_at)
df <- df[c(6, 1:5)]
write.csv(df, paste0("data/processed/study2_sample_0401/", df$screen_name[1], ".csv"))
})
df_nodate <- apply(df, 2, as.character)
View(df_nodate)
lapply(df_list, function(df) {
df_nodate <- apply(df, 2, as.character)
df_nodate <- as.data.frame(df_nodate) %>%
select(c(user_id, status_id, screen_name, text, url_t.co))
df <- cbind(df_nodate, df$created_at)
df <- df[c(6, 1:5)]
write.csv(df, paste0("data/processed/study2_sample_0401/", df$screen_name[1], ".csv"))
})
lapply(df_list, function(df) {
df_nodate <- apply(df, 2, as.character)
df_nodate <- as.data.frame(df_nodate) %>%
select(c(user_id, status_id, screen_name, text, urls_t.co))
df <- cbind(df_nodate, df$created_at)
df <- df[c(6, 1:5)]
write.csv(df, paste0("data/processed/study2_sample_0401/", df$screen_name[1], ".csv"))
})
dir <- list.files("data/processed/study2_sample_0401)
dir <- list.files("data/processed/study2_sample_0401")
for (i in 1:length(temp))
for (i in 1:length(temp)) {
for (i in 1:length(temp)) {
assign(temp[i], read.csv(paste0("data/processed/study2_sample_0401/", temp[i])))
}
for (i in 1:length(temp)) {
assign(
temp[i],
read.csv(paste0("data/processed/study2_sample_0401/", temp[i]))
)
}
for (i in 1:length(dir)) {
assign(
dir[i],
read.csv(paste0("data/processed/study2_sample_0401/", dir[i]))
)
}
dir <- list.files("data/processed/study2_sample_0401")
for (i in 1:length(dir)) {
assign(
dir[i],
read.csv(paste0("data/processed/study2_sample_0401/", dir[i]))
)
}
substr
BetterGov <- BetterGov.csv %>%
filter(!is.na(urls_t.co))
lapply(BetterGov$urls_t.co[1:30], browseURL)
here()
wkdir
wd()
getwd()
